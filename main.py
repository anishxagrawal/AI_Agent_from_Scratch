from dotenv import load_dotenv
from langchain_groq import ChatGroq
from tools import search, wikipedia, save_text_to_file

load_dotenv()

# using groq's llama model - temp=0 keeps responses consistent
llm = ChatGroq(model="llama-3.3-70b-versatile", temperature=0)

def research(query: str):
    """runs the research workflow - wiki first, then web search, then synthesize"""
    
    # try wikipedia first for background info
    print(f"üîç Step 1: Searching Wikipedia for '{query}'...")
    try:
        wiki_result = wikipedia.invoke({"query": query})
        print(f"‚úÖ Wikipedia found!\n")
    except Exception as e:
        wiki_result = f"Wikipedia search failed: {e}"
        print(f"‚ö†Ô∏è  Wikipedia error\n")
    
    # get current info from web
    print(f"üîç Step 2: Searching the web for '{query}'...")
    try:
        search_result = search.invoke({"query": query})
        print(f"‚úÖ Web search complete!\n")
    except Exception as e:
        search_result = f"Search failed: {e}"
        print(f"‚ö†Ô∏è  Search error\n")
    
    # have the LLM put it all together
    print("ü§ñ Step 3: Generating comprehensive answer...\n")
    prompt = f"""Based on the following information about "{query}", provide a clear, well-organized answer:

Wikipedia Information:
{wiki_result}

Web Search Results:
{search_result}

Task: Synthesize the above information into a comprehensive, accurate answer. Structure your response clearly."""
    
    response = llm.invoke(prompt)
    return response.content

def main():
    print("\n" + "="*70)
    print(" üî¨ AI RESEARCH ASSISTANT ".center(70))
    print("="*70)
    
    query = input("\nWhat can I help you research? ").strip()
    
    if not query:
        print("‚ùå Please provide a valid research topic.")
        return
    
    print(f"\n{'='*70}\n")
    
    try:
        # run the research
        result = research(query)
        
        # show results
        print("="*70)
        print(" üìä RESEARCH RESULTS ".center(70))
        print("="*70)
        print(f"\n{result}\n")
        print("="*70)
        
        # ask if they want to save
        save_choice = input("\nüíæ Would you like to save this research? (y/n): ").strip().lower()
        
        if save_choice == 'y':
            filename = input("üìÅ Enter filename (default: research_output.txt): ").strip()
            if not filename:
                filename = "research_output.txt"
            elif not filename.endswith('.txt'):
                filename += '.txt'
            
            # format the content nicely
            save_content = f"""RESEARCH TOPIC: {query}

{result}

---
Generated by AI Research Assistant
"""
            save_result = save_text_to_file.invoke({"data": save_content, "filename": filename})
            print(f"\n{save_result}")
        
        print("\n‚úÖ Research complete!\n")
        
    except Exception as e:
        print(f"\n‚ùå Error: {e}")
        print(f"Error type: {type(e).__name__}")

if __name__ == "__main__":
    main()